{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmg1xq2JnMtl"
      },
      "source": [
        "## Intro\n",
        "As a newly hired machine learning (ML) engineer, you have been tasked with improving 'Cat-titude Enhancer 2000,' a product that utilizes technology to monitor and enhance the well-being of cats through a play gym. The system operates by continuously streaming video footage from a camera installed in the gym, which provides input to your ML model. Based on this data, your system generates an overall recommended recipe with specific calorie counts for the cat to promote happiness, health, and strength.\n",
        "\n",
        "## Objectives\n",
        "You only deal with certain specifc backend tasks. These are your high level objectives.\n",
        "1. Improve cat image classification system. The initial cat classification model was not trained properly and this lead to some complaints from your senior ML engineer.\n",
        "2. Find a good threshold for cat image classification system. Earlier version of the model detected cat when there were none, the system ended up recommending that the cat be fed more food. Our product is being accused of producing fat cats. We must do something about it.\n",
        "3. Develop the prototype to take a 'glamour shot' of the cat with a still frame with blurred background. We get internet points if we take an amazing shot of the cat from the video and send it to owner.\n",
        "\n",
        "\n",
        "We will be using real world data, so your solutions will not be perfect. You will get full mark as long as you prove that you are capable of implementing solutions that uses the computer vision techniques and justify your answers in the context of what is asked.\n",
        "\n",
        "## Questions\n",
        "On to assignment proper. Your tasks are:\n",
        "1. Your predecessor build a training algorithm that just trained for a random number of epochs and assumed that it was the best model. Build an early stopping system for this training, ie, find the number of epochs to train, when the value of a selected quality metric is maximized. Choose an appropriate metric and justify your explanation. [10 marks]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HHtTOEMoLuG"
      },
      "source": [
        "This is the code written by your predecessor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /home/cifedior/.local/lib/python3.10/site-packages (2.2.1)\n",
            "Requirement already satisfied: torchvision in /home/cifedior/.local/lib/python3.10/site-packages (0.17.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: filelock in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: fsspec in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: networkx in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/cifedior/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/cifedior/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
            "Requirement already satisfied: numpy in /home/cifedior/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# Install touch and touch vision\n",
        "\n",
        "!pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9c4ErXSqJ2t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5323/492679038.py:10: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import mobilenet_v2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 2), (1, 3), (2, 4)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list( enumerate([2,3,4], 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "suKK_wP2SeX-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "[1,   156] loss: 0.018\n",
            "[2,   156] loss: 0.008\n",
            "[3,   156] loss: 0.006\n",
            "[4,   156] loss: 0.004\n",
            "[5,   156] loss: 0.003\n",
            "[6,   156] loss: 0.003\n",
            "[7,   156] loss: 0.002\n",
            "[8,   156] loss: 0.002\n",
            "[9,   156] loss: 0.001\n",
            "[10,   156] loss: 0.001\n",
            "[11,   156] loss: 0.001\n",
            "[12,   156] loss: 0.001\n",
            "[13,   156] loss: 0.001\n",
            "[14,   156] loss: 0.001\n",
            "[15,   156] loss: 0.001\n",
            "[16,   156] loss: 0.001\n",
            "[17,   156] loss: 0.001\n",
            "[18,   156] loss: 0.000\n",
            "[19,   156] loss: 0.000\n",
            "[20,   156] loss: 0.000\n"
          ]
        }
      ],
      "source": [
        "# Download and load the dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Filter the dataset to only include images of cats (class 3) and another class (e.g., class 0)\n",
        "dataset = [(img, label) for img, label in dataset if label in [0, 3]]\n",
        "trainset = dataset\n",
        "# Make dataloader\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model and modify last layer\n",
        "model = mobilenet_v2(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(model.last_channel, 2)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model and track metrics with MLflow\n",
        "softmax = nn.Softmax(dim=1)\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        labels = torch.where(labels==3, torch.tensor([1]), torch.tensor([0]))  # convert labels to 0/1\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 156 == 155:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 156))\n",
        "            running_loss = 0.0\n",
        "best_model = model\n",
        "THRESHOLD = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125\n",
            "32\n",
            "8000\n",
            "2000\n",
            "[1,   125] loss: 0.612\n",
            "[Epoch 1] Validation Loss: 0.154\n",
            "counter >>  0\n",
            "[2,   125] loss: 0.391\n",
            "[Epoch 2] Validation Loss: 0.113\n",
            "counter >>  0\n",
            "[3,   125] loss: 0.252\n",
            "[Epoch 3] Validation Loss: 0.095\n",
            "counter >>  0\n",
            "[4,   125] loss: 0.827\n",
            "[Epoch 4] Validation Loss: 0.155\n",
            "counter >>  1\n",
            "[5,   125] loss: 0.554\n",
            "[Epoch 5] Validation Loss: 0.166\n",
            "counter >>  2\n",
            "[6,   125] loss: 0.199\n",
            "[Epoch 6] Validation Loss: 0.138\n",
            "counter >>  3\n",
            "[7,   125] loss: 0.780\n",
            "[Epoch 7] Validation Loss: 0.147\n",
            "counter >>  4\n",
            "[8,   125] loss: 0.490\n",
            "[Epoch 8] Validation Loss: 0.098\n",
            "counter >>  5\n",
            "Early stopping triggered. Stopping training.\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = len(trainset) - train_size\n",
        "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(len(trainloader))\n",
        "print(len(valloader))\n",
        "print(train_size)\n",
        "print(val_size)\n",
        "\n",
        "\n",
        "# Initialize variables for early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "counter = 0\n",
        "\n",
        "best_model2 = None\n",
        "\n",
        "\n",
        "# Train the model and track metrics with early stopping\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        labels = torch.where(labels==3, torch.tensor([1]), torch.tensor([0]))  # convert labels to 0/1\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 125 == 124:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss))\n",
        "            # running_loss = 0.0\n",
        "    \n",
        "    # Validate the model after each epoch\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_data in valloader:\n",
        "            val_inputs, val_labels = val_data\n",
        "            val_labels = torch.where(val_labels==3, torch.tensor([1]), torch.tensor([0]))\n",
        "            \n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss += criterion(val_outputs, val_labels).item()\n",
        "    \n",
        "    # Calculate average validation loss\n",
        "    # avg_val_loss = val_loss / len(valloader)\n",
        "            \n",
        "    avg_val_loss = val_loss\n",
        "    print('[Epoch %d] Validation Loss: %.3f' % (epoch + 1, avg_val_loss))\n",
        "    \n",
        "    # Check for early stopping\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        counter = 0  # Reset counter if validation loss improves\n",
        "        best_model2 = model  # Update the best model\n",
        "    else:\n",
        "        counter += 1  # Increment counter if validation loss does not improve\n",
        "    print('counter >> ', counter)\n",
        "    # Check if early stopping criteria met\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping triggered. Stopping training.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of trainset: 10000\n"
          ]
        }
      ],
      "source": [
        "trainset_length = len(trainset)\n",
        "print(\"Length of trainset:\", trainset_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of trainloader: 157\n"
          ]
        }
      ],
      "source": [
        "trainloader_length = len(trainloader)\n",
        "print(\"Length of trainloader:\", trainloader_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "evxz0bLaKWOH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.04774435609579086"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code here\n",
        "for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    if i == 0:\n",
        "        print(len(inputs[0]))\n",
        "\n",
        "    labels = torch.where(labels==3, torch.tensor([1]), torch.tensor([0]))\n",
        "\n",
        "    outputs = best_model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "loss.item()\n",
        "\n",
        "#0.1478763073682785  epoch 2\n",
        "#0.07189879566431046 epoch 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X61WzU30KkR8"
      },
      "source": [
        "2. Compute a threshold that meets the objectives of the larger task. Explain your reasoning clearly. This is an open question, but there are certain range of metrics that makes sense here. [5 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXUKDaQCKjii"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "print(f\"New threshold is {THRESHOLD}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQg5NgZU5xfN"
      },
      "source": [
        "3. Build a cat photo capture system that stores the best image of the cat and blurs the background. We provided you with a randomly picked sample video.\n",
        "\n",
        "  For this assignment, we will define the best image as the one in which the cat occupies the most area on screen. So your objectives are\n",
        "    1. Iterate through every frame of video, use the classifer you trained with the threshold you designed to count the number of frames in which there is a cat. `[5 marks]`\n",
        "    2. If a cat is detected, segment the cat and enhance the image. The enhanced image could have either (do one of these).  `[15 marks]`\n",
        "      - Blurred background background. Use `GaussianBlur` function in opencv to achieve the blur effect.\n",
        "      - White background.      \n",
        "    3. Figure out a logic to find out the frame in which the cat occupies most area and save/display that image. The file name of that should be `cat_<current_time>_<number_of_frames>.jpg`. `[5 marks]`\n",
        "\n",
        "Notes and hints\n",
        "- The results here need not be perfect, you will have blurred image of the cat because of motion in the video. For the scope of this assignment, motion blur in the image is acceptable.\n",
        "- Use maskRCNN.\n",
        "- Use pretrained model from torch vision.  \n",
        "- Video itself is long, but for experimentation first 50 frames will be enough to get you some good samples of cats.\n",
        "- Try `sample_video2.mp4` first, then `sample_video.mp4`.\n",
        "- The videos are provided for educationl use only, from https://www.pexels.com/search/videos/cat%20jump/. Please donot redistrubute the sample videos.\n",
        "\n",
        "Here is some sample code to read the video file to get you started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfKQrFMNX2Bl",
        "outputId": "947aaaa5-eff8-4a8b-f9fb-b05a23a8400f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists! Delete the file to force download again...\n",
            "--2024-03-07 00:49:19--  https://docs.google.com/uc?export=download&id=1mkAjevnCeZDefXrDIu9N-2qIxDngPbL0&confirm=t\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.102, 142.251.2.139, 142.251.2.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1mkAjevnCeZDefXrDIu9N-2qIxDngPbL0&export=download [following]\n",
            "--2024-03-07 00:49:19--  https://drive.usercontent.google.com/download?id=1mkAjevnCeZDefXrDIu9N-2qIxDngPbL0&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.101.132, 2607:f8b0:4023:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.101.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2428 (2.4K) [text/html]\n",
            "Saving to: ‘sample_video.mp4’\n",
            "\n",
            "sample_video.mp4    100%[===================>]   2.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-07 00:49:19 (36.9 MB/s) - ‘sample_video.mp4’ saved [2428/2428]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# The code below minimizes the amount of downloads when you rerun all cells.\n",
        "# You probably don't need to download the same file over and over again...\n",
        "if os.path.isfile('sample_video2.mp4'):\n",
        "    print('File already exists! Delete the file to force download again...')\n",
        "else:\n",
        "    !wget -O sample_video2.mp4 'https://docs.google.com/uc?export=download&id=1wQDX5uu56NOLVPXQtngjeA4Cy5gygd_6&confirm=t'\n",
        "\n",
        "if os.path.isfile('sample_video.mp4'):\n",
        "    print('File already exists! Delete the file to force download again...')\n",
        "else:\n",
        "    !wget -O sample_video.mp4 'https://docs.google.com/uc?export=download&id=1mkAjevnCeZDefXrDIu9N-2qIxDngPbL0&confirm=t'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZc_5BaOuC-k"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "TOTAL_FRAME_LIMIT = 2\n",
        "framecount = 0\n",
        "\n",
        "def blur_background(image, mask):\n",
        "    out_image = image\n",
        "    # your code here\n",
        "    return out_image\n",
        "\n",
        "# your model set up code here\n",
        "\n",
        "# Read sample file and process\n",
        "cap = cv2.VideoCapture(\"sample_video2.mp4\")\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening video file\")\n",
        "    exit(1)\n",
        "\n",
        "def process_frame(frame):\n",
        "    best_image = frame\n",
        "    best_mask = None\n",
        "    # single image processing code here\n",
        "    return best_image, best_mask\n",
        "\n",
        "print(\"Processing frames...\")\n",
        "for totalframe in tqdm(range(TOTAL_FRAME_LIMIT)):\n",
        "    framecount += 1\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        best_image, best_mask= process_frame(frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "best_image = blur_background(best_image, best_mask)\n",
        "best_image = cv2.cvtColor(best_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(best_image)\n",
        "plt.title(f\"cat_{datetime.datetime.now()}_{framecount}.jpg\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkLbkPJBPixG"
      },
      "source": [
        "Extra tasks if you are interested\n",
        "- Make this real time.  \n",
        "- Use image quality metric to take the frame with the best image of the cat\n",
        "- Improve segmentation with Segment anything model."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
